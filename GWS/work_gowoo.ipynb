{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.090046700Z",
     "start_time": "2024-03-27T06:47:36.071838400Z"
    }
   },
   "outputs": [],
   "source": [
    "### 모듈 로딩\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms \n",
    "from torchvision.datasets import ImageFolder \n",
    "### ===> Module Import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset,DataLoader,WeightedRandomSampler\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copy2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.105681200Z",
     "start_time": "2024-03-27T06:47:39.091089400Z"
    }
   },
   "id": "229f5dfd9185a015",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def make_weights(labels, nclasses):\n",
    "    labels = np.array(labels)  #전체 클래스 받아서 어레이로 받고\n",
    "    weight_list = []\n",
    "\n",
    "    for cls in range(nclasses):\n",
    "        idx = np.where(labels == cls)[0]\n",
    "        count = len(idx)\n",
    "        weight = 1 / count   #역수 취하기\n",
    "        weights = [weight] * count  #\n",
    "        weight_list += weights  #리스트로 바꾸어서 리턴\n",
    "#전체 받은 샘플에 대해서 그 각각의 가중치를 적용할 수 있다. \n",
    "    return weight_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.131651300Z",
     "start_time": "2024-03-27T06:47:39.108836200Z"
    }
   },
   "id": "a6a10ac8fd930de4",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "파일 전처리 함수 만들기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a71b59557505227"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder \n",
    "\n",
    "img_root = \"./pizza_not_pizza/\" # 해당 경로 내에 있는 파일명이 곧 label이 되는 것\n",
    "train_root=\"./pizza_not_pizza/train\"\n",
    "test_root=\"./pizza_not_pizza/test\"\n",
    "validation_root=\"./pizza_not_pizza/validation\"\n",
    "\n",
    "\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "preprocessing = transforms.Compose([\n",
    "    transforms.Resize((50,50), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=mean, std=std) # 4. normalized\n",
    "])\n",
    "\n",
    "imgDS = ImageFolder(root=img_root, transform=preprocessing)\n",
    "validDS = ImageFolder(root=validation_root, transform=preprocessing)\n",
    "testDS = ImageFolder(root=test_root, transform=preprocessing)\n",
    "trainDS = ImageFolder(root=train_root, transform=preprocessing)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.155172200Z",
     "start_time": "2024-03-27T06:47:39.123325700Z"
    }
   },
   "id": "5c590809b2d53f45",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "이미지 ds 클래스 확인, 클래스를 idx로 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d3f78f1d7464102"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(['not_pizza', 'pizza'], {'not_pizza': 0, 'pizza': 1})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validDS.classes,validDS.class_to_idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.176051300Z",
     "start_time": "2024-03-27T06:47:39.156228600Z"
    }
   },
   "id": "e5783ccdcc0255df",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "weights = make_weights(imgDS.targets, len(imgDS.classes))\n",
    "weights = torch.DoubleTensor(weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.201127800Z",
     "start_time": "2024-03-27T06:47:39.170807300Z"
    }
   },
   "id": "7425e159360904a6",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "이미지 샘플러"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2064f674c194a6e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img_sampler = WeightedRandomSampler(weights, len(weights))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.202189500Z",
     "start_time": "2024-03-27T06:47:39.185436Z"
    }
   },
   "id": "34c7aa0d4758d190",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x2514e4c1a60>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgDS[400][0].permute(1,2,0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.362216800Z",
     "start_time": "2024-03-27T06:47:39.202189500Z"
    }
   },
   "id": "789e61889a70a45c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "trainDL = DataLoader(\n",
    "    trainDS, batch_size=batch_size, drop_last=True,shuffle=True\n",
    ")\n",
    "validDL = DataLoader(\n",
    "    validDS, batch_size=batch_size, drop_last=True,shuffle=True\n",
    ")\n",
    "\n",
    "testDL = DataLoader(\n",
    "    testDS, batch_size=batch_size, drop_last=True,shuffle=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.372558900Z",
     "start_time": "2024-03-27T06:47:39.358036800Z"
    }
   },
   "id": "cc4a702ff489ffb6",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "[ 이미지랑 라벨 쪽 형태 보기]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "776d69649e0bab1e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.2.0  Device: cpu\n"
     ]
    }
   ],
   "source": [
    "### ===> 딥러닝 모델을 설계할 때 활용하는 장비 확인\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.391183800Z",
     "start_time": "2024-03-27T06:47:39.373633400Z"
    }
   },
   "id": "41d31fc160b5242b",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.421344600Z",
     "start_time": "2024-03-27T06:47:39.387064200Z"
    }
   },
   "id": "7ff28ef028679ac1",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(1966, 40.0, torch.utils.data.dataloader.DataLoader)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imgDS), len(trainDS)/40, type(trainDL) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:39.422404400Z",
     "start_time": "2024-03-27T06:47:39.404766Z"
    }
   },
   "id": "a5d60b8b59348fb3",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n",
      "X_train: torch.Size([32, 3, 50, 50]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "### ===>  데이터 확인하기 (1)\n",
    "### X_train : torch.Size([32, 3, 32, 32]) [배치사이즈, 채널, 높이, 너비]\n",
    "### Y_train : torch.Size([32]) [배치사이즈] 즉, 32개 이미지에 대한 라벨\n",
    "for (X_train, y_train) in trainDL:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:44.460848500Z",
     "start_time": "2024-03-27T06:47:39.420346Z"
    }
   },
   "id": "20367458bfae61be",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(in_channels =3, out_channels = 8, kernel_size = 3, padding = 1) \n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fc1 = nn.Linear(12*12*16, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 2) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x) \n",
    "        x = self.conv2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x) \n",
    "        \n",
    "        x = x.view(-1, 12*12*16)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:44.477074800Z",
     "start_time": "2024-03-27T06:47:44.462557300Z"
    }
   },
   "id": "7965546316b19332",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2304, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### ===> Optimizer, Objective Function 설정\n",
    "model = CNN().to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 0.0001) #epoch마다 학습률을 0.001씩 줄임\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:44.496862900Z",
     "start_time": "2024-03-27T06:47:44.475011300Z"
    }
   },
   "id": "728581ad6554fb32",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# CNN 모델 학습 진행 함수\n",
    "def train(epoch, model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "           \n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx}]\\tTrain Loss: {loss.item():.6f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:44.519647500Z",
     "start_time": "2024-03-27T06:47:44.491605300Z"
    }
   },
   "id": "e0239a6049afda42",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### 검증 validation 진행 함수 \n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            # print(image, label)\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            \n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T06:47:44.520645600Z",
     "start_time": "2024-03-27T06:47:44.507238600Z"
    }
   },
   "id": "b15bd87a855dba85",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0]\tTrain Loss: 0.683422\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.0200, \tTest Accuracy: 62.65 % \n",
      "\n",
      "Train Epoch: 2 [0]\tTrain Loss: 0.645090\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0188, \tTest Accuracy: 65.66 % \n",
      "\n",
      "Train Epoch: 3 [0]\tTrain Loss: 0.637201\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0183, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 4 [0]\tTrain Loss: 0.571014\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0179, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 5 [0]\tTrain Loss: 0.662011\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.0174, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 6 [0]\tTrain Loss: 0.541860\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.0174, \tTest Accuracy: 69.88 % \n",
      "\n",
      "Train Epoch: 7 [0]\tTrain Loss: 0.611150\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.0182, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 8 [0]\tTrain Loss: 0.490077\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.0179, \tTest Accuracy: 67.47 % \n",
      "\n",
      "Train Epoch: 9 [0]\tTrain Loss: 0.463202\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.0176, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 10 [0]\tTrain Loss: 0.748399\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0178, \tTest Accuracy: 66.87 % \n",
      "\n",
      "Train Epoch: 11 [0]\tTrain Loss: 0.697621\n",
      "\n",
      "[EPOCH: 11], \tTest Loss: 0.0178, \tTest Accuracy: 67.47 % \n",
      "\n",
      "Train Epoch: 12 [0]\tTrain Loss: 0.461423\n",
      "\n",
      "[EPOCH: 12], \tTest Loss: 0.0176, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 13 [0]\tTrain Loss: 0.400413\n",
      "\n",
      "[EPOCH: 13], \tTest Loss: 0.0179, \tTest Accuracy: 67.47 % \n",
      "\n",
      "Train Epoch: 14 [0]\tTrain Loss: 0.445496\n",
      "\n",
      "[EPOCH: 14], \tTest Loss: 0.0184, \tTest Accuracy: 62.05 % \n",
      "\n",
      "Train Epoch: 15 [0]\tTrain Loss: 0.538082\n",
      "\n",
      "[EPOCH: 15], \tTest Loss: 0.0178, \tTest Accuracy: 65.66 % \n",
      "\n",
      "Train Epoch: 16 [0]\tTrain Loss: 0.491245\n",
      "\n",
      "[EPOCH: 16], \tTest Loss: 0.0177, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 17 [0]\tTrain Loss: 0.483007\n",
      "\n",
      "[EPOCH: 17], \tTest Loss: 0.0169, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 18 [0]\tTrain Loss: 0.395400\n",
      "\n",
      "[EPOCH: 18], \tTest Loss: 0.0173, \tTest Accuracy: 72.89 % \n",
      "\n",
      "Train Epoch: 19 [0]\tTrain Loss: 0.439020\n",
      "\n",
      "[EPOCH: 19], \tTest Loss: 0.0172, \tTest Accuracy: 72.29 % \n",
      "\n",
      "Train Epoch: 20 [0]\tTrain Loss: 0.416136\n",
      "\n",
      "[EPOCH: 20], \tTest Loss: 0.0169, \tTest Accuracy: 72.29 % \n",
      "\n",
      "Train Epoch: 21 [0]\tTrain Loss: 0.276009\n",
      "\n",
      "[EPOCH: 21], \tTest Loss: 0.0169, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 22 [0]\tTrain Loss: 0.374358\n",
      "\n",
      "[EPOCH: 22], \tTest Loss: 0.0165, \tTest Accuracy: 74.10 % \n",
      "\n",
      "Train Epoch: 23 [0]\tTrain Loss: 0.352514\n",
      "\n",
      "[EPOCH: 23], \tTest Loss: 0.0164, \tTest Accuracy: 72.89 % \n",
      "\n",
      "Train Epoch: 24 [0]\tTrain Loss: 0.305198\n",
      "\n",
      "[EPOCH: 24], \tTest Loss: 0.0166, \tTest Accuracy: 73.49 % \n",
      "\n",
      "Train Epoch: 25 [0]\tTrain Loss: 0.375718\n",
      "\n",
      "[EPOCH: 25], \tTest Loss: 0.0167, \tTest Accuracy: 73.49 % \n",
      "\n",
      "Train Epoch: 26 [0]\tTrain Loss: 0.168207\n",
      "\n",
      "[EPOCH: 26], \tTest Loss: 0.0174, \tTest Accuracy: 67.47 % \n",
      "\n",
      "Train Epoch: 27 [0]\tTrain Loss: 0.420484\n",
      "\n",
      "[EPOCH: 27], \tTest Loss: 0.0165, \tTest Accuracy: 74.10 % \n",
      "\n",
      "Train Epoch: 28 [0]\tTrain Loss: 0.381570\n",
      "\n",
      "[EPOCH: 28], \tTest Loss: 0.0164, \tTest Accuracy: 75.30 % \n",
      "Train Epoch: 29 [0]\tTrain Loss: 0.270016\n",
      "\n",
      "[EPOCH: 29], \tTest Loss: 0.0162, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 30 [0]\tTrain Loss: 0.365833\n",
      "\n",
      "[EPOCH: 30], \tTest Loss: 0.0165, \tTest Accuracy: 72.29 % \n",
      "\n",
      "Train Epoch: 31 [0]\tTrain Loss: 0.333460\n",
      "\n",
      "[EPOCH: 31], \tTest Loss: 0.0163, \tTest Accuracy: 72.89 % \n",
      "\n",
      "Train Epoch: 32 [0]\tTrain Loss: 0.267334\n",
      "\n",
      "[EPOCH: 32], \tTest Loss: 0.0173, \tTest Accuracy: 72.89 % \n",
      "\n",
      "Train Epoch: 33 [0]\tTrain Loss: 0.321098\n",
      "\n",
      "[EPOCH: 33], \tTest Loss: 0.0187, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 34 [0]\tTrain Loss: 0.318837\n",
      "\n",
      "[EPOCH: 34], \tTest Loss: 0.0168, \tTest Accuracy: 75.30 % \n",
      "\n",
      "Train Epoch: 35 [0]\tTrain Loss: 0.370146\n",
      "\n",
      "[EPOCH: 35], \tTest Loss: 0.0168, \tTest Accuracy: 72.89 % \n",
      "\n",
      "Train Epoch: 36 [0]\tTrain Loss: 0.234004\n",
      "\n",
      "[EPOCH: 36], \tTest Loss: 0.0174, \tTest Accuracy: 72.29 % \n",
      "\n",
      "Train Epoch: 37 [0]\tTrain Loss: 0.299113\n",
      "\n",
      "[EPOCH: 37], \tTest Loss: 0.0176, \tTest Accuracy: 75.90 % \n",
      "\n",
      "Train Epoch: 38 [0]\tTrain Loss: 0.346273\n",
      "\n",
      "[EPOCH: 38], \tTest Loss: 0.0182, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 39 [0]\tTrain Loss: 0.493906\n",
      "\n",
      "[EPOCH: 39], \tTest Loss: 0.0185, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 40 [0]\tTrain Loss: 0.256908\n",
      "\n",
      "[EPOCH: 40], \tTest Loss: 0.0176, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 41 [0]\tTrain Loss: 0.373016\n",
      "\n",
      "[EPOCH: 41], \tTest Loss: 0.0172, \tTest Accuracy: 73.49 % \n",
      "\n",
      "Train Epoch: 42 [0]\tTrain Loss: 0.177322\n",
      "\n",
      "[EPOCH: 42], \tTest Loss: 0.0178, \tTest Accuracy: 72.29 % \n",
      "\n",
      "Train Epoch: 43 [0]\tTrain Loss: 0.291333\n",
      "\n",
      "[EPOCH: 43], \tTest Loss: 0.0190, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 44 [0]\tTrain Loss: 0.202767\n",
      "\n",
      "[EPOCH: 44], \tTest Loss: 0.0182, \tTest Accuracy: 69.88 % \n",
      "\n",
      "Train Epoch: 45 [0]\tTrain Loss: 0.142150\n",
      "\n",
      "[EPOCH: 45], \tTest Loss: 0.0187, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 46 [0]\tTrain Loss: 0.216723\n",
      "\n",
      "[EPOCH: 46], \tTest Loss: 0.0193, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 47 [0]\tTrain Loss: 0.110445\n",
      "\n",
      "[EPOCH: 47], \tTest Loss: 0.0193, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 48 [0]\tTrain Loss: 0.202509\n",
      "\n",
      "[EPOCH: 48], \tTest Loss: 0.0197, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 49 [0]\tTrain Loss: 0.268432\n",
      "\n",
      "[EPOCH: 49], \tTest Loss: 0.0200, \tTest Accuracy: 72.29 % \n",
      "\n",
      "Train Epoch: 50 [0]\tTrain Loss: 0.142478\n",
      "\n",
      "[EPOCH: 50], \tTest Loss: 0.0192, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 51 [0]\tTrain Loss: 0.319349\n",
      "\n",
      "[EPOCH: 51], \tTest Loss: 0.0208, \tTest Accuracy: 69.88 % \n",
      "\n",
      "Train Epoch: 52 [0]\tTrain Loss: 0.240188\n",
      "\n",
      "[EPOCH: 52], \tTest Loss: 0.0208, \tTest Accuracy: 69.28 % \n",
      "Train Epoch: 53 [0]\tTrain Loss: 0.160391\n",
      "\n",
      "[EPOCH: 53], \tTest Loss: 0.0204, \tTest Accuracy: 73.49 % \n",
      "\n",
      "Train Epoch: 54 [0]\tTrain Loss: 0.141994\n",
      "\n",
      "[EPOCH: 54], \tTest Loss: 0.0218, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 55 [0]\tTrain Loss: 0.207385\n",
      "\n",
      "[EPOCH: 55], \tTest Loss: 0.0216, \tTest Accuracy: 69.88 % \n",
      "\n",
      "Train Epoch: 56 [0]\tTrain Loss: 0.185346\n",
      "\n",
      "[EPOCH: 56], \tTest Loss: 0.0225, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 57 [0]\tTrain Loss: 0.088979\n",
      "\n",
      "[EPOCH: 57], \tTest Loss: 0.0220, \tTest Accuracy: 72.89 % \n",
      "\n",
      "Train Epoch: 58 [0]\tTrain Loss: 0.240387\n",
      "\n",
      "[EPOCH: 58], \tTest Loss: 0.0241, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 59 [0]\tTrain Loss: 0.261718\n",
      "\n",
      "[EPOCH: 59], \tTest Loss: 0.0230, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 60 [0]\tTrain Loss: 0.139884\n",
      "\n",
      "[EPOCH: 60], \tTest Loss: 0.0236, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 61 [0]\tTrain Loss: 0.072386\n",
      "\n",
      "[EPOCH: 61], \tTest Loss: 0.0241, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 62 [0]\tTrain Loss: 0.134019\n",
      "\n",
      "[EPOCH: 62], \tTest Loss: 0.0232, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 63 [0]\tTrain Loss: 0.121808\n",
      "\n",
      "[EPOCH: 63], \tTest Loss: 0.0230, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 64 [0]\tTrain Loss: 0.123482\n",
      "\n",
      "[EPOCH: 64], \tTest Loss: 0.0252, \tTest Accuracy: 69.88 % \n",
      "\n",
      "Train Epoch: 65 [0]\tTrain Loss: 0.062437\n",
      "\n",
      "[EPOCH: 65], \tTest Loss: 0.0244, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 66 [0]\tTrain Loss: 0.053332\n",
      "\n",
      "[EPOCH: 66], \tTest Loss: 0.0264, \tTest Accuracy: 69.88 % \n",
      "\n",
      "Train Epoch: 67 [0]\tTrain Loss: 0.208013\n",
      "\n",
      "[EPOCH: 67], \tTest Loss: 0.0251, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 68 [0]\tTrain Loss: 0.113653\n",
      "\n",
      "[EPOCH: 68], \tTest Loss: 0.0253, \tTest Accuracy: 68.07 % \n",
      "Train Epoch: 69 [0]\tTrain Loss: 0.033014\n",
      "\n",
      "[EPOCH: 69], \tTest Loss: 0.0258, \tTest Accuracy: 68.07 % \n",
      "Train Epoch: 70 [0]\tTrain Loss: 0.085611\n",
      "\n",
      "[EPOCH: 70], \tTest Loss: 0.0273, \tTest Accuracy: 68.67 % \n",
      "Train Epoch: 71 [0]\tTrain Loss: 0.087743\n",
      "\n",
      "[EPOCH: 71], \tTest Loss: 0.0279, \tTest Accuracy: 68.07 % \n",
      "Train Epoch: 72 [0]\tTrain Loss: 0.144164\n",
      "\n",
      "[EPOCH: 72], \tTest Loss: 0.0290, \tTest Accuracy: 67.47 % \n",
      "\n",
      "Train Epoch: 73 [0]\tTrain Loss: 0.097896\n",
      "\n",
      "[EPOCH: 73], \tTest Loss: 0.0279, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 74 [0]\tTrain Loss: 0.155042\n",
      "\n",
      "[EPOCH: 74], \tTest Loss: 0.0284, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 75 [0]\tTrain Loss: 0.085393\n",
      "\n",
      "[EPOCH: 75], \tTest Loss: 0.0293, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 76 [0]\tTrain Loss: 0.023491\n",
      "\n",
      "[EPOCH: 76], \tTest Loss: 0.0287, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 77 [0]\tTrain Loss: 0.033349\n",
      "\n",
      "[EPOCH: 77], \tTest Loss: 0.0311, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 78 [0]\tTrain Loss: 0.087170\n",
      "\n",
      "[EPOCH: 78], \tTest Loss: 0.0311, \tTest Accuracy: 69.88 % \n",
      "\n",
      "Train Epoch: 79 [0]\tTrain Loss: 0.074561\n",
      "\n",
      "[EPOCH: 79], \tTest Loss: 0.0322, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 80 [0]\tTrain Loss: 0.096427\n",
      "\n",
      "[EPOCH: 80], \tTest Loss: 0.0324, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 81 [0]\tTrain Loss: 0.063452\n",
      "\n",
      "[EPOCH: 81], \tTest Loss: 0.0313, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 82 [0]\tTrain Loss: 0.046678\n",
      "\n",
      "[EPOCH: 82], \tTest Loss: 0.0318, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 83 [0]\tTrain Loss: 0.060122\n",
      "\n",
      "[EPOCH: 83], \tTest Loss: 0.0331, \tTest Accuracy: 66.87 % \n",
      "\n",
      "Train Epoch: 84 [0]\tTrain Loss: 0.057121\n",
      "\n",
      "[EPOCH: 84], \tTest Loss: 0.0330, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 85 [0]\tTrain Loss: 0.042247\n",
      "\n",
      "[EPOCH: 85], \tTest Loss: 0.0322, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 86 [0]\tTrain Loss: 0.045641\n",
      "\n",
      "[EPOCH: 86], \tTest Loss: 0.0314, \tTest Accuracy: 68.67 % \n",
      "Train Epoch: 87 [0]\tTrain Loss: 0.031141\n",
      "\n",
      "[EPOCH: 87], \tTest Loss: 0.0352, \tTest Accuracy: 68.07 % \n",
      "Train Epoch: 88 [0]\tTrain Loss: 0.026759\n",
      "\n",
      "[EPOCH: 88], \tTest Loss: 0.0346, \tTest Accuracy: 67.47 % \n",
      "Train Epoch: 89 [0]\tTrain Loss: 0.025413\n",
      "\n",
      "[EPOCH: 89], \tTest Loss: 0.0351, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 90 [0]\tTrain Loss: 0.037076\n",
      "\n",
      "[EPOCH: 90], \tTest Loss: 0.0363, \tTest Accuracy: 66.87 % \n",
      "\n",
      "Train Epoch: 91 [0]\tTrain Loss: 0.012204\n",
      "\n",
      "[EPOCH: 91], \tTest Loss: 0.0354, \tTest Accuracy: 69.28 % \n",
      "\n",
      "Train Epoch: 92 [0]\tTrain Loss: 0.034292\n",
      "\n",
      "[EPOCH: 92], \tTest Loss: 0.0369, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 93 [0]\tTrain Loss: 0.030710\n",
      "\n",
      "[EPOCH: 93], \tTest Loss: 0.0363, \tTest Accuracy: 71.08 % \n",
      "\n",
      "Train Epoch: 94 [0]\tTrain Loss: 0.043456\n",
      "\n",
      "[EPOCH: 94], \tTest Loss: 0.0365, \tTest Accuracy: 70.48 % \n",
      "\n",
      "Train Epoch: 95 [0]\tTrain Loss: 0.038966\n",
      "\n",
      "[EPOCH: 95], \tTest Loss: 0.0348, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 96 [0]\tTrain Loss: 0.021060\n",
      "\n",
      "[EPOCH: 96], \tTest Loss: 0.0378, \tTest Accuracy: 68.07 % \n",
      "\n",
      "Train Epoch: 97 [0]\tTrain Loss: 0.022018\n",
      "\n",
      "[EPOCH: 97], \tTest Loss: 0.0385, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 98 [0]\tTrain Loss: 0.015807\n",
      "\n",
      "[EPOCH: 98], \tTest Loss: 0.0388, \tTest Accuracy: 68.67 % \n",
      "\n",
      "Train Epoch: 99 [0]\tTrain Loss: 0.018380\n",
      "\n",
      "[EPOCH: 99], \tTest Loss: 0.0392, \tTest Accuracy: 67.47 % \n",
      "\n",
      "Train Epoch: 100 [0]\tTrain Loss: 0.013135\n",
      "\n",
      "[EPOCH: 100], \tTest Loss: 0.0395, \tTest Accuracy: 66.87 % \n"
     ]
    }
   ],
   "source": [
    "# CNN 학습\n",
    "EPOCHS =100\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    \n",
    "    train(epoch, model,trainDL, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, testDL)\n",
    "    \n",
    "    print(f\"\\n[EPOCH: {epoch}], \\tTest Loss: {test_loss:.4f}, \\tTest Accuracy: {test_accuracy:.2f} % \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T07:02:58.271681400Z",
     "start_time": "2024-03-27T06:47:44.522687100Z"
    }
   },
   "id": "d27c31bac3db01f0",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T07:02:58.280155600Z",
     "start_time": "2024-03-27T07:02:58.274670200Z"
    }
   },
   "id": "54cea10ab65f420a",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ALEXNET 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bd93230f302f168"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "63fc0277a28fe7ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18,ResNet18_Weights,AlexNet\n",
    "\n",
    "#데이터 모델 학습 준비 \n",
    "model = AlexNet(num_classes=2) # 클래스 수에 맞춰 출력 레이어 수정\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# 데이터 재설정 \n",
    "\n",
    "ALEXPREPRO = transforms.Compose([\n",
    "    transforms.Resize(256),  # 이미지를 리사이징\n",
    "    transforms.CenterCrop(224),  # 이미지 중심부 자르기\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 데이터셋과 데이터로더 생성\n",
    "ALEXvalidDS = ImageFolder(root=validation_root, transform=ALEXPREPRO)\n",
    "ALEXtestDS = ImageFolder(root=test_root, transform=ALEXPREPRO)\n",
    "ALEXtrainDS = ImageFolder(root=train_root, transform=ALEXPREPRO)\n",
    "\n",
    "ALEXtrainDL = DataLoader(ALEXtrainDS, batch_size=32, shuffle=True)\n",
    "ALEXvalidDL = DataLoader(ALEXvalidDS, batch_size=32, shuffle=False)\n",
    "ALEXtestDL = DataLoader(ALEXtestDS, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T07:02:58.755447Z",
     "start_time": "2024-03-27T07:02:58.286239800Z"
    }
   },
   "id": "1de77fd4eef50cfe",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T07:02:58.769311900Z",
     "start_time": "2024-03-27T07:02:58.756443700Z"
    }
   },
   "id": "8d5e6275b19aeaba",
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
